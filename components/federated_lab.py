import streamlit as st
import torch
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from typing import Dict, List, Optional
import json
from datetime import datetime, timedelta


class FederatedLabComponent:
    """Advanced federated learning and AutoML interface"""
    
    def __init__(self):
        self.initialize_platform()
    
    def initialize_platform(self):
        """Initialize federated learning platform"""
        try:
            from models.federated_learning import BiomolecularFoundationPlatform
            self.platform = BiomolecularFoundationPlatform()
            
            # Initialize session state
            if 'federated_experiments' not in st.session_state:
                st.session_state.federated_experiments = {}
            
            if 'automl_results' not in st.session_state:
                st.session_state.automl_results = {}
                
        except Exception as e:
            st.error(f"Error initializing federated platform: {str(e)}")
    
    def render(self):
        """Render federated learning interface"""
        st.header("üåê Federated Learning & AutoML Laboratory")
        st.markdown("Secure multi-institutional collaboration and automated model optimization")
        
        tab1, tab2, tab3, tab4 = st.tabs([
            "Federated Learning", 
            "AutoML Optimization", 
            "Institution Management", 
            "Experiment Monitoring"
        ])
        
        with tab1:
            self.render_federated_learning()
        
        with tab2:
            self.render_automl()
        
        with tab3:
            self.render_institution_management()
        
        with tab4:
            self.render_experiment_monitoring()
    
    def render_federated_learning(self):
        """Render federated learning setup and execution"""
        st.subheader("üîó Federated Learning Setup")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.write("**Create New Experiment**")
            
            experiment_name = st.text_input(
                "Experiment Name:",
                placeholder="biomolecular_discovery_2025"
            )
            
            model_type = st.selectbox(
                "Base Model Type:",
                ["BiomolecularLLM", "HybridPredictor", "ProteinFolder"]
            )
            
            # Model configuration
            st.write("**Model Configuration:**")
            embed_dim = st.selectbox("Embedding Dimension:", [128, 256, 512, 1024], index=1)
            num_layers = st.slider("Number of Layers:", 4, 16, 8)
            num_heads = st.selectbox("Attention Heads:", [4, 8, 12, 16], index=1)
            
            privacy_level = st.selectbox(
                "Privacy Level:",
                ["Basic", "Differential Privacy", "Secure Aggregation", "Full Privacy"]
            )
            
            if st.button("Create Federated Experiment", type="primary"):
                config = {
                    'embed_dim': embed_dim,
                    'num_layers': num_layers,
                    'num_heads': num_heads,
                    'privacy_level': privacy_level
                }
                
                experiment = self.platform.create_federated_experiment(experiment_name, config)
                st.session_state.federated_experiments[experiment_name] = experiment
                st.success(f"Created experiment: {experiment_name}")
        
        with col2:
            st.write("**Add Institutions**")
            
            if st.session_state.federated_experiments:
                selected_exp = st.selectbox(
                    "Select Experiment:",
                    list(st.session_state.federated_experiments.keys())
                )
                
                institution_name = st.text_input(
                    "Institution Name:",
                    placeholder="MIT_BioChem_Lab"
                )
                
                data_size = st.number_input(
                    "Local Dataset Size:",
                    min_value=100,
                    max_value=100000,
                    value=5000
                )
                
                data_type = st.selectbox(
                    "Data Type:",
                    ["Protein Sequences", "Drug Molecules", "Binding Assays", "Structure Data"]
                )
                
                if st.button("Add Institution") and institution_name:
                    try:
                        if selected_exp:
                            federated_model = self.platform.add_institution(
                                selected_exp, institution_name, data_size
                            )
                        
                        # Update session state
                        exp_data = st.session_state.federated_experiments[selected_exp]
                        exp_data['participants'].append({
                            'name': institution_name,
                            'data_size': data_size,
                            'data_type': data_type,
                            'joined': datetime.now()
                        })
                        
                        st.success(f"Added {institution_name} to experiment")
                        
                    except Exception as e:
                        st.error(f"Error adding institution: {str(e)}")
        
        # Federated Training Controls
        if st.session_state.federated_experiments:
            st.subheader("üîÑ Federated Training")
            
            selected_exp = st.selectbox(
                "Select Experiment for Training:",
                list(st.session_state.federated_experiments.keys()),
                key="training_exp"
            )
            
            col1, col2, col3 = st.columns([1, 1, 1])
            
            with col1:
                num_rounds = st.number_input("Training Rounds:", 1, 50, 5)
            
            with col2:
                local_epochs = st.number_input("Local Epochs:", 1, 20, 3)
            
            with col3:
                if st.button("Start Federated Training", type="primary"):
                    with st.spinner("Running federated training..."):
                        progress_bar = st.progress(0)
                        
                        results = []
                        for round_num in range(num_rounds):
                            # Run federated round
                            round_result = self.platform.run_federated_round(selected_exp)
                            results.append(round_result)
                            
                            progress_bar.progress((round_num + 1) / num_rounds)
                        
                        st.session_state.federated_results = results
                        st.success(f"Completed {num_rounds} federated rounds!")
            
            # Display results
            if 'federated_results' in st.session_state:
                st.subheader("Training Results")
                
                results = st.session_state.federated_results
                
                # Summary metrics
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Rounds Completed", len(results))
                
                with col2:
                    total_participants = sum(r['num_participants'] for r in results)
                    st.metric("Total Participations", total_participants)
                
                with col3:
                    avg_participants = total_participants / len(results) if results else 0
                    st.metric("Avg Participants/Round", f"{avg_participants:.1f}")
                
                with col4:
                    st.metric("Privacy Level", "Secured ‚úì")
                
                # Training progress chart
                fig = go.Figure()
                rounds = list(range(1, len(results) + 1))
                participants = [r['num_participants'] for r in results]
                
                fig.add_trace(go.Scatter(
                    x=rounds,
                    y=participants,
                    mode='lines+markers',
                    name='Participants per Round'
                ))
                
                fig.update_layout(
                    title="Federated Training Progress",
                    xaxis_title="Training Round",
                    yaxis_title="Number of Participants",
                    height=300
                )
                st.plotly_chart(fig, use_container_width=True)
    
    def render_automl(self):
        """Render AutoML optimization interface"""
        st.subheader("ü§ñ AutoML Architecture Search")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.write("**Optimization Configuration**")
            
            optimization_target = st.selectbox(
                "Optimization Target:",
                ["Validation Accuracy", "Training Speed", "Model Size", "Energy Efficiency"]
            )
            
            search_strategy = st.selectbox(
                "Search Strategy:",
                ["Random Search", "Bayesian Optimization", "Evolutionary", "Neural Architecture Search"]
            )
            
            num_trials = st.slider("Number of Trials:", 5, 100, 20)
            
            # Search space configuration
            st.write("**Search Space:**")
            embed_dims = st.multiselect(
                "Embedding Dimensions:",
                [64, 128, 256, 512, 1024],
                default=[128, 256, 512]
            )
            
            layer_range = st.slider("Layer Range:", 2, 20, (4, 12))
            
            if st.button("Start AutoML Optimization", type="primary"):
                with st.spinner("Running AutoML optimization..."):
                    progress_bar = st.progress(0)
                    
                    # Update search space
                    self.platform.automl_optimizer.search_space.update({
                        'embed_dim': embed_dims,
                        'num_layers': list(range(layer_range[0], layer_range[1] + 1))
                    })
                    
                    # Run optimization
                    optimization_results = self.platform.optimize_architecture(
                        "automl_experiment", num_trials
                    )
                    
                    progress_bar.progress(1.0)
                    st.session_state.automl_results = optimization_results
                    st.success("AutoML optimization completed!")
        
        with col2:
            st.write("**Optimization Results**")
            
            if 'automl_results' in st.session_state and st.session_state.automl_results:
                results = st.session_state.automl_results
                
                if 'best_config' in results and results['best_config']:
                    st.write("**Best Configuration Found:**")
                    
                    best_config = results['best_config']
                    
                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.metric("Best Score", f"{results['best_score']:.4f}")
                        st.metric("Embed Dim", best_config['embed_dim'])
                        st.metric("Layers", best_config['num_layers'])
                    
                    with col_b:
                        st.metric("Trials Run", results['total_trials'])
                        st.metric("Avg Score", f"{results['mean_score']:.4f}")
                        st.metric("Improvement", f"{results['improvement']:.4f}")
                    
                    # Configuration details
                    with st.expander("Full Configuration"):
                        st.json(best_config)
                
                else:
                    st.info("No optimization results available yet.")
        
        # AutoML Progress Visualization
        if ('automl_results' in st.session_state and 
            st.session_state.automl_results and 
            'total_trials' in st.session_state.automl_results):
            
            st.subheader("Optimization Progress")
            
            # Generate sample trial data for visualization
            trials_data = []
            best_score = st.session_state.automl_results['best_score']
            num_trials = st.session_state.automl_results['total_trials']
            
            # Simulate trial progression
            current_best = 0.3
            for i in range(num_trials):
                # Simulate some improvement over time
                score = np.random.uniform(0.3, best_score) if i < num_trials - 5 else best_score
                if score > current_best:
                    current_best = score
                
                trials_data.append({
                    'trial': i + 1,
                    'score': score,
                    'best_so_far': current_best
                })
            
            df = pd.DataFrame(trials_data)
            
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=df['trial'],
                y=df['score'],
                mode='markers',
                name='Trial Score',
                marker=dict(color='lightblue', size=8)
            ))
            
            fig.add_trace(go.Scatter(
                x=df['trial'],
                y=df['best_so_far'],
                mode='lines',
                name='Best Score',
                line=dict(color='red', width=3)
            ))
            
            fig.update_layout(
                title="AutoML Optimization Progress",
                xaxis_title="Trial Number",
                yaxis_title="Model Score",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def render_institution_management(self):
        """Render institution management interface"""
        st.subheader("üèõÔ∏è Institution Management")
        
        # Institution overview
        if st.session_state.federated_experiments:
            st.write("**Current Institutions**")
            
            all_institutions = []
            for exp_name, exp_data in st.session_state.federated_experiments.items():
                for participant in exp_data.get('participants', []):
                    all_institutions.append({
                        'Experiment': exp_name,
                        'Institution': participant.get('name', 'Unknown'),
                        'Data Size': participant.get('data_size', 0),
                        'Data Type': participant.get('data_type', 'Unknown'),
                        'Joined': participant.get('joined', datetime.now()).strftime('%Y-%m-%d')
                    })
            
            if all_institutions:
                df = pd.DataFrame(all_institutions)
                st.dataframe(df, use_container_width=True)
                
                # Institution statistics
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Total Institutions", len(all_institutions))
                
                with col2:
                    total_data = sum(inst['Data Size'] for inst in all_institutions)
                    st.metric("Total Data Points", f"{total_data:,}")
                
                with col3:
                    unique_experiments = len(set(inst['Experiment'] for inst in all_institutions))
                    st.metric("Active Experiments", unique_experiments)
                
                # Data distribution
                if len(all_institutions) > 1:
                    fig = px.pie(
                        df, 
                        values='Data Size', 
                        names='Institution',
                        title="Data Distribution Across Institutions"
                    )
                    st.plotly_chart(fig, use_container_width=True)
            
            else:
                st.info("No institutions registered yet.")
        
        else:
            st.info("No federated experiments created yet.")
        
        # Privacy and Security Settings
        st.subheader("üîí Privacy & Security")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Privacy Settings**")
            
            dp_enabled = st.checkbox("Differential Privacy", value=True)
            if dp_enabled:
                noise_scale = st.slider("Noise Scale:", 0.01, 1.0, 0.1)
            
            secure_agg = st.checkbox("Secure Aggregation", value=True)
            encryption = st.checkbox("End-to-End Encryption", value=True)
        
        with col2:
            st.write("**Security Status**")
            
            security_items = [
                ("Data Encryption", "‚úÖ Active"),
                ("Model Encryption", "‚úÖ Active"),
                ("Communication Security", "‚úÖ TLS 1.3"),
                ("Access Control", "‚úÖ Multi-factor"),
                ("Audit Logging", "‚úÖ Enabled")
            ]
            
            for item, status in security_items:
                st.write(f"**{item}:** {status}")
    
    def render_experiment_monitoring(self):
        """Render experiment monitoring and analytics"""
        st.subheader("üìä Experiment Monitoring")
        
        if not st.session_state.federated_experiments:
            st.info("No experiments to monitor yet.")
            return
        
        # Experiment selector
        selected_exp = st.selectbox(
            "Select Experiment to Monitor:",
            list(st.session_state.federated_experiments.keys())
        )
        
        exp_data = st.session_state.federated_experiments[selected_exp]
        
        # Experiment overview
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Status", exp_data.get('status', 'Unknown'))
        
        with col2:
            participants = len(exp_data.get('participants', []))
            st.metric("Participants", participants)
        
        with col3:
            rounds = exp_data.get('rounds_completed', 0)
            st.metric("Rounds Completed", rounds)
        
        with col4:
            created = exp_data.get('created', datetime.now())
            runtime = datetime.now() - created
            st.metric("Runtime", f"{runtime.days}d {runtime.seconds//3600}h")
        
        # Experiment configuration
        with st.expander("Experiment Configuration"):
            config = exp_data.get('config', {})
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Model Parameters:**")
                for key, value in config.items():
                    st.write(f"- **{key}:** {value}")
            
            with col2:
                st.write("**Experiment Details:**")
                st.write(f"- **Created:** {created.strftime('%Y-%m-%d %H:%M')}")
                st.write(f"- **Experiment ID:** {selected_exp}")
                st.write(f"- **Privacy Level:** {config.get('privacy_level', 'Standard')}")
        
        # Performance metrics
        st.subheader("Performance Metrics")
        
        # Simulate performance data
        if 'federated_results' in st.session_state:
            results = st.session_state.federated_results
            
            # Create performance timeline
            timeline_data = []
            for i, result in enumerate(results):
                timeline_data.append({
                    'Round': i + 1,
                    'Participants': result['num_participants'],
                    'Convergence': np.random.uniform(0.7, 0.95),  # Simulated
                    'Privacy_Score': np.random.uniform(0.8, 1.0),  # Simulated
                    'Efficiency': np.random.uniform(0.6, 0.9)  # Simulated
                })
            
            df = pd.DataFrame(timeline_data)
            
            # Multi-metric chart
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=df['Round'], y=df['Convergence'],
                mode='lines+markers', name='Model Convergence'
            ))
            
            fig.add_trace(go.Scatter(
                x=df['Round'], y=df['Privacy_Score'],
                mode='lines+markers', name='Privacy Score'
            ))
            
            fig.add_trace(go.Scatter(
                x=df['Round'], y=df['Efficiency'],
                mode='lines+markers', name='Training Efficiency'
            ))
            
            fig.update_layout(
                title="Federated Learning Performance",
                xaxis_title="Training Round",
                yaxis_title="Score",
                height=400,
                yaxis=dict(range=[0, 1])
            )
            st.plotly_chart(fig, use_container_width=True)
        
        else:
            st.info("No performance data available yet. Run federated training to see metrics.")
        
        # System resources
        st.subheader("System Resources")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Simulate resource usage
            cpu_usage = np.random.uniform(20, 80)
            st.metric("CPU Usage", f"{cpu_usage:.1f}%")
            
            fig = go.Figure(go.Indicator(
                mode="gauge+number",
                value=cpu_usage,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "CPU"},
                gauge={'axis': {'range': [None, 100]},
                       'bar': {'color': "darkblue"},
                       'steps': [{'range': [0, 50], 'color': "lightgray"},
                                {'range': [50, 80], 'color': "yellow"},
                                {'range': [80, 100], 'color': "red"}]}
            ))
            fig.update_layout(height=200)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            memory_usage = np.random.uniform(30, 70)
            st.metric("Memory Usage", f"{memory_usage:.1f}%")
            
            fig = go.Figure(go.Indicator(
                mode="gauge+number",
                value=memory_usage,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "Memory"},
                gauge={'axis': {'range': [None, 100]},
                       'bar': {'color': "darkgreen"},
                       'steps': [{'range': [0, 50], 'color': "lightgray"},
                                {'range': [50, 80], 'color': "yellow"},
                                {'range': [80, 100], 'color': "red"}]}
            ))
            fig.update_layout(height=200)
            st.plotly_chart(fig, use_container_width=True)
        
        with col3:
            network_usage = np.random.uniform(10, 60)
            st.metric("Network Usage", f"{network_usage:.1f}%")
            
            fig = go.Figure(go.Indicator(
                mode="gauge+number",
                value=network_usage,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "Network"},
                gauge={'axis': {'range': [None, 100]},
                       'bar': {'color': "darkorange"},
                       'steps': [{'range': [0, 50], 'color': "lightgray"},
                                {'range': [50, 80], 'color': "yellow"},
                                {'range': [80, 100], 'color': "red"}]}
            ))
            fig.update_layout(height=200)
            st.plotly_chart(fig, use_container_width=True)
